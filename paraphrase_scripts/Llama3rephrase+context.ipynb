{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PHsz3wuLVAj"
   },
   "source": [
    "# Rephrase csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xSqIfQrJ51j",
    "outputId": "40872d15-41ff-4a0e-830e-6a7a5a999775",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.42.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.local/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.10/site-packages (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0a0+29c30b1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.10/site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0a0+29c30b1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: bitsandbytes in ./.local/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.0a0+29c30b1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install torch\n",
    "!pip install bitsandbytes\n",
    "\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyacaIKNLSrR"
   },
   "source": [
    "Load your CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVhscx7JKFof",
    "outputId": "29adca77-be52-4d67-f517-f1981b3694cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.744077</td>\n",
       "      <td>0.967634</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>322</td>\n",
       "      <td>351</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Hello, Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.178846</td>\n",
       "      <td>1.267935</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>365</td>\n",
       "      <td>403</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Welcome to my channel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.780447</td>\n",
       "      <td>1.468135</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>413</td>\n",
       "      <td>457</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Please click on SUBSCRIBE!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.182850</td>\n",
       "      <td>3.503504</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>485</td>\n",
       "      <td>590</td>\n",
       "      <td>29.97</td>\n",
       "      <td>We will teaching you about fast food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.487154</td>\n",
       "      <td>1.067734</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>614</td>\n",
       "      <td>646</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Are you ready???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595419</th>\n",
       "      <td>124.991658</td>\n",
       "      <td>3.003003</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>3746</td>\n",
       "      <td>3836</td>\n",
       "      <td>29.97</td>\n",
       "      <td>kind (nice &amp; sweet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595420</th>\n",
       "      <td>128.995662</td>\n",
       "      <td>2.002002</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>3866</td>\n",
       "      <td>3926</td>\n",
       "      <td>29.97</td>\n",
       "      <td>give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595421</th>\n",
       "      <td>131.998665</td>\n",
       "      <td>8.975642</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>3956</td>\n",
       "      <td>4225</td>\n",
       "      <td>29.97</td>\n",
       "      <td>cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595422</th>\n",
       "      <td>141.975309</td>\n",
       "      <td>6.006006</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>4255</td>\n",
       "      <td>4435</td>\n",
       "      <td>29.97</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595423</th>\n",
       "      <td>155.488822</td>\n",
       "      <td>3.503504</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>4660</td>\n",
       "      <td>4765</td>\n",
       "      <td>29.97</td>\n",
       "      <td>gift, present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595424 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1            2     3     4      5  \\\n",
       "0        10.744077  0.967634  2M83YRjnHWs   322   351  29.97   \n",
       "1        12.178846  1.267935  2M83YRjnHWs   365   403  29.97   \n",
       "2        13.780447  1.468135  2M83YRjnHWs   413   457  29.97   \n",
       "3        16.182850  3.503504  2M83YRjnHWs   485   590  29.97   \n",
       "4        20.487154  1.067734  2M83YRjnHWs   614   646  29.97   \n",
       "...            ...       ...          ...   ...   ...    ...   \n",
       "595419  124.991658  3.003003  35-h2dH-sf0  3746  3836  29.97   \n",
       "595420  128.995662  2.002002  35-h2dH-sf0  3866  3926  29.97   \n",
       "595421  131.998665  8.975642  35-h2dH-sf0  3956  4225  29.97   \n",
       "595422  141.975309  6.006006  35-h2dH-sf0  4255  4435  29.97   \n",
       "595423  155.488822  3.503504  35-h2dH-sf0  4660  4765  29.97   \n",
       "\n",
       "                                            6  \n",
       "0                               Hello, Hello!  \n",
       "1                      Welcome to my channel.  \n",
       "2                Please click on SUBSCRIBE!!!  \n",
       "3       We will teaching you about fast food.  \n",
       "4                            Are you ready???  \n",
       "...                                       ...  \n",
       "595419                    kind (nice & sweet)  \n",
       "595420                                   give  \n",
       "595421                                 cookie  \n",
       "595422                                   milk  \n",
       "595423                          gift, present  \n",
       "\n",
       "[595424 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.filtered3.beg_dur_id_frames_fps_text.norm.filter-lanid.tsv', sep='\\t', header=None)\n",
    "\n",
    "sentences = df[6].astype(str).tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Beg(s)</th>\n",
       "      <th>Dur(s)</th>\n",
       "      <th>YouTubeID</th>\n",
       "      <th>StartFrame</th>\n",
       "      <th>EndFrame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2M83YRjnHWs.000322-000351</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>322</td>\n",
       "      <td>351</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Hello, Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2M83YRjnHWs.000365-000403</td>\n",
       "      <td>12.18</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>365</td>\n",
       "      <td>403</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Welcome to my channel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2M83YRjnHWs.000413-000457</td>\n",
       "      <td>13.78</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>413</td>\n",
       "      <td>457</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Please click on SUBSCRIBE!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2M83YRjnHWs.000485-000590</td>\n",
       "      <td>16.18</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>485</td>\n",
       "      <td>590</td>\n",
       "      <td>29.97</td>\n",
       "      <td>We will teaching you about fast food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2M83YRjnHWs.000614-000646</td>\n",
       "      <td>20.49</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2M83YRjnHWs</td>\n",
       "      <td>614</td>\n",
       "      <td>646</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Are you ready???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595419</th>\n",
       "      <td>35-h2dH-sf0.003746-003836</td>\n",
       "      <td>124.99</td>\n",
       "      <td>3.00</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>3746</td>\n",
       "      <td>3836</td>\n",
       "      <td>29.97</td>\n",
       "      <td>kind (nice &amp; sweet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595420</th>\n",
       "      <td>35-h2dH-sf0.003866-003926</td>\n",
       "      <td>129.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>3866</td>\n",
       "      <td>3926</td>\n",
       "      <td>29.97</td>\n",
       "      <td>give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595421</th>\n",
       "      <td>35-h2dH-sf0.003956-004225</td>\n",
       "      <td>132.00</td>\n",
       "      <td>8.98</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>3956</td>\n",
       "      <td>4225</td>\n",
       "      <td>29.97</td>\n",
       "      <td>cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595422</th>\n",
       "      <td>35-h2dH-sf0.004255-004435</td>\n",
       "      <td>141.98</td>\n",
       "      <td>6.01</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>4255</td>\n",
       "      <td>4435</td>\n",
       "      <td>29.97</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595423</th>\n",
       "      <td>35-h2dH-sf0.004660-004765</td>\n",
       "      <td>155.49</td>\n",
       "      <td>3.50</td>\n",
       "      <td>35-h2dH-sf0</td>\n",
       "      <td>4660</td>\n",
       "      <td>4765</td>\n",
       "      <td>29.97</td>\n",
       "      <td>gift, present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595424 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ClipID  Beg(s)  Dur(s)    YouTubeID  StartFrame  \\\n",
       "0       2M83YRjnHWs.000322-000351   10.74    0.97  2M83YRjnHWs         322   \n",
       "1       2M83YRjnHWs.000365-000403   12.18    1.27  2M83YRjnHWs         365   \n",
       "2       2M83YRjnHWs.000413-000457   13.78    1.47  2M83YRjnHWs         413   \n",
       "3       2M83YRjnHWs.000485-000590   16.18    3.50  2M83YRjnHWs         485   \n",
       "4       2M83YRjnHWs.000614-000646   20.49    1.07  2M83YRjnHWs         614   \n",
       "...                           ...     ...     ...          ...         ...   \n",
       "595419  35-h2dH-sf0.003746-003836  124.99    3.00  35-h2dH-sf0        3746   \n",
       "595420  35-h2dH-sf0.003866-003926  129.00    2.00  35-h2dH-sf0        3866   \n",
       "595421  35-h2dH-sf0.003956-004225  132.00    8.98  35-h2dH-sf0        3956   \n",
       "595422  35-h2dH-sf0.004255-004435  141.98    6.01  35-h2dH-sf0        4255   \n",
       "595423  35-h2dH-sf0.004660-004765  155.49    3.50  35-h2dH-sf0        4660   \n",
       "\n",
       "        EndFrame    FPS                                Caption  \n",
       "0            351  29.97                          Hello, Hello!  \n",
       "1            403  29.97                 Welcome to my channel.  \n",
       "2            457  29.97           Please click on SUBSCRIBE!!!  \n",
       "3            590  29.97  We will teaching you about fast food.  \n",
       "4            646  29.97                       Are you ready???  \n",
       "...          ...    ...                                    ...  \n",
       "595419      3836  29.97                    kind (nice & sweet)  \n",
       "595420      3926  29.97                                   give  \n",
       "595421      4225  29.97                                 cookie  \n",
       "595422      4435  29.97                                   milk  \n",
       "595423      4765  29.97                          gift, present  \n",
       "\n",
       "[595424 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Beg(s)', 'Dur(s)', 'YouTubeID', 'StartFrame', 'EndFrame', 'FPS', 'Caption']\n",
    "df.columns = columns\n",
    "df[['Beg(s)', 'Dur(s)']] = df[['Beg(s)', 'Dur(s)']].map(lambda x: float(f\"{x:.2f}\"))\n",
    "num_rephrases = 5\n",
    "version_columns = [f'Llama3_Rephrase{i+1}' for i in range(num_rephrases)]\n",
    "\n",
    "df['ClipID'] = df.apply(lambda row: f\"{row['YouTubeID']}.{row['StartFrame']:06d}-{row['EndFrame']:06d}\", axis=1)\n",
    "df = df[['ClipID'] + [col for col in df.columns if col != 'ClipID']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2M8tIslkofz"
   },
   "source": [
    "# Llama3rephrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "umbElgkfLQwT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.23s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "HF_TOKEN = \"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\"\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"text-generation\",\n",
    "  model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "  model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "  device=\"cuda\",\n",
    "  token=HF_TOKEN)\n",
    "\n",
    "terminators = [\n",
    "    pipe.tokenizer.eos_token_id,\n",
    "    pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase_sentence(sentence, num, context):\n",
    "\n",
    "    if num == 1:\n",
    "        messages=[\n",
    "      {\"role\": \"system\", \"content\": f\"You are a helpful assistant that rephrases a given sentence. Try to be semantically consistent. Here is some additional context to help you understand the subject and style:\\n\\n{context}\\n\\n Make sure the paraphrase includes all the information from the original sentence, don't output any other text.\"},\n",
    "      {\"role\": \"user\", \"content\": f\"{sentence}\"}]\n",
    "    else:\n",
    "        messages=[\n",
    "      {\"role\": \"system\", \"content\": f\"You are a helpful assistant that rephrases a given sentence in {num} ways, each on its own line. Try to be semantically consistent and maintain the key elements. Here is some additional context to help you understand the subject and style:\\n\\n{context}\\n\\nYou don't output any other text than these sentences.\"},\n",
    "      {\"role\": \"user\", \"content\": f\"{sentence}\"}]\n",
    "\n",
    "    pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=8192,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        pad_token_id = pipe.tokenizer.eos_token_id)\n",
    "\n",
    "    return outputs[0][\"generated_text\"][-1][\"content\"].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PmwJhjYOpyp",
    "outputId": "5530b666-0d57-42dc-c4c7-9e4c518ad6e5"
   },
   "outputs": [],
   "source": [
    "rephrase_sentence(\"Edgar Allan Poe lived in Baltimore during the 1830s and is buried there.\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(rephrase_sentence(\"Edgar Allan Poe lived in Baltimore during the 1830s and is buried there.\",1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_YTID(line):\n",
    "    return df['YouTubeID'][line]\n",
    "\n",
    "def lowercase_first_letter(text):\n",
    "    return re.sub(r'^[A-Z]', lambda x: x.group(0).lower(), text)\n",
    "\n",
    "def add_context(line, prev_context = None):\n",
    "    last_line = sentences[line-1]\n",
    "    \n",
    "    if prev_context == None:\n",
    "        return last_line\n",
    "    else:\n",
    "        if re.search(r'[.!?]$', prev_context):\n",
    "            return \" \".join([prev_context, last_line])\n",
    "        else:\n",
    "            return \" \".join([prev_context, lowercase_first_letter(last_line)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMQxoOGw5L5A",
    "outputId": "48e5bf31-84cd-4d27-b40a-10e451233117",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rephrasing: lines 0 to 29999:\n",
      "1 / 30000 (0.0 %) - Line 0\n",
      "1  gift, present hello, Hello!\n",
      "Welcome to my channel.\n",
      "2 / 30000 (0.01 %) - Line 1\n",
      "2  gift, present hello, Hello! Welcome to my channel.\n",
      "Please click on SUBSCRIBE!!!\n",
      "3 / 30000 (0.01 %) - Line 2\n",
      "3  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!!\n",
      "We will teaching you about fast food.\n",
      "4 / 30000 (0.01 %) - Line 3\n",
      "5 / 30000 (0.02 %) - Line 4\n",
      "6 / 30000 (0.02 %) - Line 5\n",
      "6  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure???\n",
      "First restaurant is my favorite most the world.\n",
      "7 / 30000 (0.02 %) - Line 6\n",
      "8 / 30000 (0.03 %) - Line 7\n",
      "9 / 30000 (0.03 %) - Line 8\n",
      "10 / 30000 (0.03 %) - Line 9\n",
      "10  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure??? First restaurant is my favorite most the world. Subway pizza Hut mcdonald\n",
      "I used to be young kid and when i was ate mcdonald.\n",
      "11 / 30000 (0.04 %) - Line 10\n",
      "12 / 30000 (0.04 %) - Line 11\n",
      "13 / 30000 (0.04 %) - Line 12\n",
      "14 / 30000 (0.05 %) - Line 13\n",
      "15 / 30000 (0.05 %) - Line 14\n",
      "16 / 30000 (0.05 %) - Line 15\n",
      "17 / 30000 (0.06 %) - Line 16\n",
      "18 / 30000 (0.06 %) - Line 17\n",
      "19 / 30000 (0.06 %) - Line 18\n",
      "20 / 30000 (0.07 %) - Line 19\n",
      "21 / 30000 (0.07 %) - Line 20\n",
      "22 / 30000 (0.07 %) - Line 21\n",
      "23 / 30000 (0.08 %) - Line 22\n",
      "24 / 30000 (0.08 %) - Line 23\n",
      "24  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure??? First restaurant is my favorite most the world. Subway pizza Hut mcdonald i used to be young kid and when i was ate mcdonald. EWWWW! Starbucks dunkin' Donuts taco Bell wendy's burger King mexican food domino's Pizza panda Express little Caesars kFC sonic in-N-OUT Burger\n",
      "That's my second favorite restaurant for fast food.\n",
      "25 / 30000 (0.08 %) - Line 24\n",
      "26 / 30000 (0.09 %) - Line 25\n",
      "26  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure??? First restaurant is my favorite most the world. Subway pizza Hut mcdonald i used to be young kid and when i was ate mcdonald. EWWWW! Starbucks dunkin' Donuts taco Bell wendy's burger King mexican food domino's Pizza panda Express little Caesars kFC sonic in-N-OUT Burger that's my second favorite restaurant for fast food. Chipotle\n",
      "Jack in the box\n",
      "27 / 30000 (0.09 %) - Line 26\n",
      "28 / 30000 (0.09 %) - Line 27\n",
      "29 / 30000 (0.1 %) - Line 28\n",
      "30 / 30000 (0.1 %) - Line 29\n",
      "30  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure??? First restaurant is my favorite most the world. Subway pizza Hut mcdonald i used to be young kid and when i was ate mcdonald. EWWWW! Starbucks dunkin' Donuts taco Bell wendy's burger King mexican food domino's Pizza panda Express little Caesars kFC sonic in-N-OUT Burger that's my second favorite restaurant for fast food. Chipotle jack in the box popeyes panera five guys\n",
      "Thank you for watching this video .\n",
      "31 / 30000 (0.1 %) - Line 30\n",
      "31  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure??? First restaurant is my favorite most the world. Subway pizza Hut mcdonald i used to be young kid and when i was ate mcdonald. EWWWW! Starbucks dunkin' Donuts taco Bell wendy's burger King mexican food domino's Pizza panda Express little Caesars kFC sonic in-N-OUT Burger that's my second favorite restaurant for fast food. Chipotle jack in the box popeyes panera five guys thank you for watching this video .\n",
      "Don't forget click subscribe and likes and notifications\n",
      "32 / 30000 (0.11 %) - Line 31\n",
      "32  gift, present hello, Hello! Welcome to my channel. Please click on SUBSCRIBE!!! We will teaching you about fast food. Are you ready??? Are you sure??? First restaurant is my favorite most the world. Subway pizza Hut mcdonald i used to be young kid and when i was ate mcdonald. EWWWW! Starbucks dunkin' Donuts taco Bell wendy's burger King mexican food domino's Pizza panda Express little Caesars kFC sonic in-N-OUT Burger that's my second favorite restaurant for fast food. Chipotle jack in the box popeyes panera five guys thank you for watching this video . Don't forget click subscribe and likes and notifications\n",
      "Thank you and Bye!!\n",
      "33 / 30000 (0.11 %) - Line 32\n",
      "33 \n",
      "Blood circulates throughout the body\n",
      "34 / 30000 (0.11 %) - Line 33\n",
      "34  blood circulates throughout the body\n",
      "But it also seeps into the soil\n",
      "35 / 30000 (0.12 %) - Line 34\n",
      "36 / 30000 (0.12 %) - Line 35\n",
      "36  blood circulates throughout the body but it also seeps into the soil across continents\n",
      "Mixing into the oceans\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(line, context)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence)\n\u001b[0;32m---> 38\u001b[0m rephrased_versions \u001b[38;5;241m=\u001b[39m \u001b[43mrephrase_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rephrases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rephrased_versions)):\n\u001b[1;32m     40\u001b[0m   rephrased_versions[i] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m. |- \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, rephrased_versions[i]) \u001b[38;5;66;03m# remove gpt's 1. or -\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mrephrase_sentence\u001b[0;34m(sentence, num, context)\u001b[0m\n\u001b[1;32m      8\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      9\u001b[0m   {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that rephrases a given sentence in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ways, each on its own line. Try to be semantically consistent and maintain the key elements. Here is some additional context to help you understand the subject and style:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt output any other text than these sentences.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m   {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m     12\u001b[0m pipe\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:257\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    253\u001b[0m     text_inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, KeyDataset) \u001b[38;5;28;01mif\u001b[39;00m is_torch_available() \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m    254\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_inputs[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_inputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 257\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m         chats \u001b[38;5;241m=\u001b[39m [Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs]  \u001b[38;5;66;03m# 🐈 🐈 🐈\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1254\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         )\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1261\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1260\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1261\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:349\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1174\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1171\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:978\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    967\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    968\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    969\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         cache_position,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:718\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:352\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m causal_mask\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(query_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    353\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    354\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1831\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m-> 1831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a softmax function.\u001b[39;00m\n\u001b[1;32m   1833\u001b[0m \n\u001b[1;32m   1834\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Params\n",
    "startline = 0 # counting from 0\n",
    "batch = 30000\n",
    "endline = startline + batch # this line is not processed\n",
    "num_rephrases = 5\n",
    "min_words = 4\n",
    "max_words = 30\n",
    "checkpoint_freq = 100\n",
    "\n",
    "rephrased_data = []\n",
    "c = 0\n",
    "prev_YTID = get_YTID(0)\n",
    "context = \"\"\n",
    "\n",
    "def save_checkpoint(rephrased_data, startline, c):\n",
    "    rephrased_data = [[item for item in row if item] for row in rephrased_data] # Remove empty strings using list comprehension\n",
    "    for i in range(len(rephrased_data)):\n",
    "        if len(rephrased_data[i]) != num_rephrases:\n",
    "            rephrased_data[i] = [\"<none>\"] * num_rephrases\n",
    "    df_rephrases = pd.DataFrame(rephrased_data, columns=version_columns)\n",
    "    result = pd.concat([df.iloc[:startline], pd.concat([df.iloc[startline:].reset_index(drop=True), df_rephrases.reset_index(drop=True)], axis=1)], ignore_index=True)\n",
    "    result.to_csv(f'llama_rephrases+c/l3rephrased+c_{startline}-{startline+c-1}.csv', index=False)\n",
    "    return rephrased_data\n",
    "    \n",
    "print(f\"Starting rephrasing: lines {startline} to {endline-1}:\")\n",
    "    \n",
    "for line, sentence in enumerate(sentences[startline:endline]):\n",
    "    \n",
    "    if get_YTID(line) == prev_YTID: # are we still in the same video\n",
    "        context = add_context(line, context) # add prev line to the context\n",
    "    else:\n",
    "        context = \"\" # reset context\n",
    "    prev_YTID = get_YTID(line)\n",
    "    \n",
    "    if len(sentence.split()) >= min_words and len(sentence.split()) <= max_words:\n",
    "      rephrased_versions = rephrase_sentence(sentence, num_rephrases, context)\n",
    "      for i in range(len(rephrased_versions)):\n",
    "        rephrased_versions[i] = re.sub(r\"^\\d+\\. |- \", \"\", rephrased_versions[i]) # remove gpt's 1. or -\n",
    "        rephrased_versions[i] = rephrased_versions[i].strip()\n",
    "      rephrased_data.append(rephrased_versions)\n",
    "    else:\n",
    "        rephrased_data.append([\"<none>\"] * num_rephrases)\n",
    "    c += 1\n",
    "    print(f\"{c} / {batch} ({round((c/batch)*100, 2)} %) - Line {startline+c-1}\")\n",
    "    \n",
    "    if c % checkpoint_freq == 0:\n",
    "        print(\"Saving checkpoint...\")\n",
    "        rephrased_data = save_checkpoint(rephrased_data, startline, c)\n",
    "        \n",
    "rephrased_data = save_checkpoint(rephrased_data, startline, c)\n",
    "print(f\"Rephrasing done, saved (lines {startline} to {endline-1}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmue8Iks0jl0",
    "outputId": "48caa2b9-ee4b-4832-8d56-c2b825f1556f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for nonstandard outputs\n",
    "import numpy as np\n",
    "print(len(rephrased_data))\n",
    "c = 0\n",
    "for i in range(len(rephrased_data)):\n",
    "    if len(rephrased_data[i]) != num_rephrases:\n",
    "      print(len(rephrased_data[i]),f\" ({i})\")\n",
    "      print(rephrased_data[i])\n",
    "      c = c+1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrased_data = [[item for item in row if item] for row in rephrased_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge parallel csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.read_csv(f'rephrases/rephrased_0-48.csv', low_memory=False)\n",
    "merge2 = pd.read_csv(f'rephrases/rephrased_49-58.csv', low_memory=False)\n",
    "merge = merge1.combine_first(merge2).reset_index()\n",
    "merge.to_csv(f'rephrases/rephrased_0-58.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.3001791.pbs-m1.metacentrum.cz/ipykernel_545491/551634371.py:1: DtypeWarning: Columns (8,9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merge1 = pd.read_csv(f'rephrases/rephrased_0-48.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Beg(s)</th>\n",
       "      <th>Dur(s)</th>\n",
       "      <th>YouTubeID</th>\n",
       "      <th>StartFrame</th>\n",
       "      <th>EndFrame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Caption</th>\n",
       "      <th>GPT_Rephrase1</th>\n",
       "      <th>GPT_Rephrase2</th>\n",
       "      <th>GPT_Rephrase3</th>\n",
       "      <th>GPT_Rephrase4</th>\n",
       "      <th>GPT_Rephrase5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>59gGMhffroM.001980-002034</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>1980</td>\n",
       "      <td>2034</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Blood leaks out</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>59gGMhffroM.002049-002140</td>\n",
       "      <td>68.30</td>\n",
       "      <td>3.03</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2049</td>\n",
       "      <td>2140</td>\n",
       "      <td>30.00</td>\n",
       "      <td>But that blood is still the same blood</td>\n",
       "      <td>Yet, that blood remains the identical blood.</td>\n",
       "      <td>Nevertheless, that blood has not changed.</td>\n",
       "      <td>However, the blood is still the very same blood.</td>\n",
       "      <td>Even so, that blood continues to be the same.</td>\n",
       "      <td>Nonetheless, the blood remains unchanged.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>59gGMhffroM.002140-002312</td>\n",
       "      <td>71.33</td>\n",
       "      <td>5.73</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2140</td>\n",
       "      <td>2312</td>\n",
       "      <td>30.00</td>\n",
       "      <td>That carried generations of trauma</td>\n",
       "      <td>Generations of trauma were carried within it.</td>\n",
       "      <td>It held the burden of trauma passed down throu...</td>\n",
       "      <td>It bore the weight of trauma spanning across g...</td>\n",
       "      <td>This burden of trauma had been carried for gen...</td>\n",
       "      <td>The deep-rooted trauma spanned through many ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>59gGMhffroM.002312-002379</td>\n",
       "      <td>77.07</td>\n",
       "      <td>2.23</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2312</td>\n",
       "      <td>2379</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Across continents</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>59gGMhffroM.002379-002520</td>\n",
       "      <td>79.30</td>\n",
       "      <td>4.70</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2379</td>\n",
       "      <td>2520</td>\n",
       "      <td>30.00</td>\n",
       "      <td>And across oceans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>59gGMhffroM.002660-002914</td>\n",
       "      <td>88.67</td>\n",
       "      <td>8.47</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2660</td>\n",
       "      <td>2914</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Circulating in my body as of this very moment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>59gGMhffroM.002938-003170</td>\n",
       "      <td>97.93</td>\n",
       "      <td>7.73</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2938</td>\n",
       "      <td>3170</td>\n",
       "      <td>30.00</td>\n",
       "      <td>The human body can't survive without water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>59gGMhffroM.003170-003355</td>\n",
       "      <td>105.67</td>\n",
       "      <td>6.17</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>3170</td>\n",
       "      <td>3355</td>\n",
       "      <td>30.00</td>\n",
       "      <td>But the heart still needs to pump blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>61yO6Y8dgXw.000007-000157</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>61yO6Y8dgXw</td>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Deaf people can qualify for Medicare or Medicaid.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>61yO6Y8dgXw.000160-000203</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1.43</td>\n",
       "      <td>61yO6Y8dgXw</td>\n",
       "      <td>160</td>\n",
       "      <td>203</td>\n",
       "      <td>29.97</td>\n",
       "      <td>What's the difference?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ClipID  Beg(s)  Dur(s)    YouTubeID  StartFrame  \\\n",
       "45  59gGMhffroM.001980-002034   66.00    1.80  59gGMhffroM        1980   \n",
       "46  59gGMhffroM.002049-002140   68.30    3.03  59gGMhffroM        2049   \n",
       "47  59gGMhffroM.002140-002312   71.33    5.73  59gGMhffroM        2140   \n",
       "48  59gGMhffroM.002312-002379   77.07    2.23  59gGMhffroM        2312   \n",
       "49  59gGMhffroM.002379-002520   79.30    4.70  59gGMhffroM        2379   \n",
       "50  59gGMhffroM.002660-002914   88.67    8.47  59gGMhffroM        2660   \n",
       "51  59gGMhffroM.002938-003170   97.93    7.73  59gGMhffroM        2938   \n",
       "52  59gGMhffroM.003170-003355  105.67    6.17  59gGMhffroM        3170   \n",
       "53  61yO6Y8dgXw.000007-000157    0.23    5.01  61yO6Y8dgXw           7   \n",
       "54  61yO6Y8dgXw.000160-000203    5.34    1.43  61yO6Y8dgXw         160   \n",
       "\n",
       "    EndFrame    FPS                                            Caption  \\\n",
       "45      2034  30.00                                    Blood leaks out   \n",
       "46      2140  30.00             But that blood is still the same blood   \n",
       "47      2312  30.00                 That carried generations of trauma   \n",
       "48      2379  30.00                                  Across continents   \n",
       "49      2520  30.00                                  And across oceans   \n",
       "50      2914  30.00      Circulating in my body as of this very moment   \n",
       "51      3170  30.00         The human body can't survive without water   \n",
       "52      3355  30.00            But the heart still needs to pump blood   \n",
       "53       157  29.97  Deaf people can qualify for Medicare or Medicaid.   \n",
       "54       203  29.97                             What's the difference?   \n",
       "\n",
       "                                    GPT_Rephrase1  \\\n",
       "45                                         <none>   \n",
       "46   Yet, that blood remains the identical blood.   \n",
       "47  Generations of trauma were carried within it.   \n",
       "48                                         <none>   \n",
       "49                                            NaN   \n",
       "50                                            NaN   \n",
       "51                                            NaN   \n",
       "52                                            NaN   \n",
       "53                                            NaN   \n",
       "54                                            NaN   \n",
       "\n",
       "                                        GPT_Rephrase2  \\\n",
       "45                                             <none>   \n",
       "46          Nevertheless, that blood has not changed.   \n",
       "47  It held the burden of trauma passed down throu...   \n",
       "48                                             <none>   \n",
       "49                                                NaN   \n",
       "50                                                NaN   \n",
       "51                                                NaN   \n",
       "52                                                NaN   \n",
       "53                                                NaN   \n",
       "54                                                NaN   \n",
       "\n",
       "                                        GPT_Rephrase3  \\\n",
       "45                                             <none>   \n",
       "46   However, the blood is still the very same blood.   \n",
       "47  It bore the weight of trauma spanning across g...   \n",
       "48                                             <none>   \n",
       "49                                                NaN   \n",
       "50                                                NaN   \n",
       "51                                                NaN   \n",
       "52                                                NaN   \n",
       "53                                                NaN   \n",
       "54                                                NaN   \n",
       "\n",
       "                                        GPT_Rephrase4  \\\n",
       "45                                             <none>   \n",
       "46      Even so, that blood continues to be the same.   \n",
       "47  This burden of trauma had been carried for gen...   \n",
       "48                                             <none>   \n",
       "49                                                NaN   \n",
       "50                                                NaN   \n",
       "51                                                NaN   \n",
       "52                                                NaN   \n",
       "53                                                NaN   \n",
       "54                                                NaN   \n",
       "\n",
       "                                        GPT_Rephrase5  \n",
       "45                                             <none>  \n",
       "46          Nonetheless, the blood remains unchanged.  \n",
       "47  The deep-rooted trauma spanned through many ge...  \n",
       "48                                             <none>  \n",
       "49                                                NaN  \n",
       "50                                                NaN  \n",
       "51                                                NaN  \n",
       "52                                                NaN  \n",
       "53                                                NaN  \n",
       "54                                                NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge1 = pd.read_csv(f'rephrases/rephrased_0-48.csv')\n",
    "merge1.iloc[45:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.3001791.pbs-m1.metacentrum.cz/ipykernel_545491/2348484468.py:1: DtypeWarning: Columns (8,9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merge2 = pd.read_csv(f'rephrases/rephrased_49-58.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Beg(s)</th>\n",
       "      <th>Dur(s)</th>\n",
       "      <th>YouTubeID</th>\n",
       "      <th>StartFrame</th>\n",
       "      <th>EndFrame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Caption</th>\n",
       "      <th>GPT_Rephrase1</th>\n",
       "      <th>GPT_Rephrase2</th>\n",
       "      <th>GPT_Rephrase3</th>\n",
       "      <th>GPT_Rephrase4</th>\n",
       "      <th>GPT_Rephrase5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>59gGMhffroM.001980-002034</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>1980</td>\n",
       "      <td>2034</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Blood leaks out</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>59gGMhffroM.002049-002140</td>\n",
       "      <td>68.30</td>\n",
       "      <td>3.03</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2049</td>\n",
       "      <td>2140</td>\n",
       "      <td>30.00</td>\n",
       "      <td>But that blood is still the same blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>59gGMhffroM.002140-002312</td>\n",
       "      <td>71.33</td>\n",
       "      <td>5.73</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2140</td>\n",
       "      <td>2312</td>\n",
       "      <td>30.00</td>\n",
       "      <td>That carried generations of trauma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>59gGMhffroM.002312-002379</td>\n",
       "      <td>77.07</td>\n",
       "      <td>2.23</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2312</td>\n",
       "      <td>2379</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Across continents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>59gGMhffroM.002379-002520</td>\n",
       "      <td>79.30</td>\n",
       "      <td>4.70</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2379</td>\n",
       "      <td>2520</td>\n",
       "      <td>30.00</td>\n",
       "      <td>And across oceans</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>59gGMhffroM.002660-002914</td>\n",
       "      <td>88.67</td>\n",
       "      <td>8.47</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2660</td>\n",
       "      <td>2914</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Circulating in my body as of this very moment</td>\n",
       "      <td>Currently coursing through my veins</td>\n",
       "      <td>Presently flowing within me</td>\n",
       "      <td>In my bloodstream right now</td>\n",
       "      <td>As of this moment, circulating in my body</td>\n",
       "      <td>Running through me at this very second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>59gGMhffroM.002938-003170</td>\n",
       "      <td>97.93</td>\n",
       "      <td>7.73</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2938</td>\n",
       "      <td>3170</td>\n",
       "      <td>30.00</td>\n",
       "      <td>The human body can't survive without water</td>\n",
       "      <td>Water is essential for the survival of the hum...</td>\n",
       "      <td>Without water, the human body cannot endure.</td>\n",
       "      <td>The human body requires water in order to live.</td>\n",
       "      <td>Survival of the human body is impossible witho...</td>\n",
       "      <td>Water is a necessity for the human body to sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>59gGMhffroM.003170-003355</td>\n",
       "      <td>105.67</td>\n",
       "      <td>6.17</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>3170</td>\n",
       "      <td>3355</td>\n",
       "      <td>30.00</td>\n",
       "      <td>But the heart still needs to pump blood</td>\n",
       "      <td>However, the heart must continue pumping blood.</td>\n",
       "      <td>Still, blood circulation requires the heart to...</td>\n",
       "      <td>Nevertheless, the heart remains responsible fo...</td>\n",
       "      <td>Yet, blood flow necessitates the ongoing actio...</td>\n",
       "      <td>Nonetheless, the heart must persist in its fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>61yO6Y8dgXw.000007-000157</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>61yO6Y8dgXw</td>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Deaf people can qualify for Medicare or Medicaid.</td>\n",
       "      <td>Individuals who are deaf are eligible for Medi...</td>\n",
       "      <td>Deaf individuals have the possibility to meet ...</td>\n",
       "      <td>Medicare or Medicaid can be accessible to peop...</td>\n",
       "      <td>Qualification for Medicare or Medicaid is open...</td>\n",
       "      <td>Those who are deaf may be eligible for Medicar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>61yO6Y8dgXw.000160-000203</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1.43</td>\n",
       "      <td>61yO6Y8dgXw</td>\n",
       "      <td>160</td>\n",
       "      <td>203</td>\n",
       "      <td>29.97</td>\n",
       "      <td>What's the difference?</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ClipID  Beg(s)  Dur(s)    YouTubeID  StartFrame  \\\n",
       "45  59gGMhffroM.001980-002034   66.00    1.80  59gGMhffroM        1980   \n",
       "46  59gGMhffroM.002049-002140   68.30    3.03  59gGMhffroM        2049   \n",
       "47  59gGMhffroM.002140-002312   71.33    5.73  59gGMhffroM        2140   \n",
       "48  59gGMhffroM.002312-002379   77.07    2.23  59gGMhffroM        2312   \n",
       "49  59gGMhffroM.002379-002520   79.30    4.70  59gGMhffroM        2379   \n",
       "50  59gGMhffroM.002660-002914   88.67    8.47  59gGMhffroM        2660   \n",
       "51  59gGMhffroM.002938-003170   97.93    7.73  59gGMhffroM        2938   \n",
       "52  59gGMhffroM.003170-003355  105.67    6.17  59gGMhffroM        3170   \n",
       "53  61yO6Y8dgXw.000007-000157    0.23    5.01  61yO6Y8dgXw           7   \n",
       "54  61yO6Y8dgXw.000160-000203    5.34    1.43  61yO6Y8dgXw         160   \n",
       "\n",
       "    EndFrame    FPS                                            Caption  \\\n",
       "45      2034  30.00                                    Blood leaks out   \n",
       "46      2140  30.00             But that blood is still the same blood   \n",
       "47      2312  30.00                 That carried generations of trauma   \n",
       "48      2379  30.00                                  Across continents   \n",
       "49      2520  30.00                                  And across oceans   \n",
       "50      2914  30.00      Circulating in my body as of this very moment   \n",
       "51      3170  30.00         The human body can't survive without water   \n",
       "52      3355  30.00            But the heart still needs to pump blood   \n",
       "53       157  29.97  Deaf people can qualify for Medicare or Medicaid.   \n",
       "54       203  29.97                             What's the difference?   \n",
       "\n",
       "                                        GPT_Rephrase1  \\\n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                             <none>   \n",
       "50                Currently coursing through my veins   \n",
       "51  Water is essential for the survival of the hum...   \n",
       "52    However, the heart must continue pumping blood.   \n",
       "53  Individuals who are deaf are eligible for Medi...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase2  \\\n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                             <none>   \n",
       "50                        Presently flowing within me   \n",
       "51       Without water, the human body cannot endure.   \n",
       "52  Still, blood circulation requires the heart to...   \n",
       "53  Deaf individuals have the possibility to meet ...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase3  \\\n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                             <none>   \n",
       "50                        In my bloodstream right now   \n",
       "51    The human body requires water in order to live.   \n",
       "52  Nevertheless, the heart remains responsible fo...   \n",
       "53  Medicare or Medicaid can be accessible to peop...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase4  \\\n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                             <none>   \n",
       "50          As of this moment, circulating in my body   \n",
       "51  Survival of the human body is impossible witho...   \n",
       "52  Yet, blood flow necessitates the ongoing actio...   \n",
       "53  Qualification for Medicare or Medicaid is open...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase5  \n",
       "45                                                NaN  \n",
       "46                                                NaN  \n",
       "47                                                NaN  \n",
       "48                                                NaN  \n",
       "49                                             <none>  \n",
       "50             Running through me at this very second  \n",
       "51  Water is a necessity for the human body to sta...  \n",
       "52  Nonetheless, the heart must persist in its fun...  \n",
       "53  Those who are deaf may be eligible for Medicar...  \n",
       "54                                             <none>  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2 = pd.read_csv(f'rephrases/rephrased_49-58.csv')\n",
    "merge2.iloc[45:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Beg(s)</th>\n",
       "      <th>Dur(s)</th>\n",
       "      <th>YouTubeID</th>\n",
       "      <th>StartFrame</th>\n",
       "      <th>EndFrame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Caption</th>\n",
       "      <th>GPT_Rephrase1</th>\n",
       "      <th>GPT_Rephrase2</th>\n",
       "      <th>GPT_Rephrase3</th>\n",
       "      <th>GPT_Rephrase4</th>\n",
       "      <th>GPT_Rephrase5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>59gGMhffroM.001980-002034</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>1980</td>\n",
       "      <td>2034</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Blood leaks out</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>59gGMhffroM.002049-002140</td>\n",
       "      <td>68.30</td>\n",
       "      <td>3.03</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2049</td>\n",
       "      <td>2140</td>\n",
       "      <td>30.00</td>\n",
       "      <td>But that blood is still the same blood</td>\n",
       "      <td>Yet, that blood remains the identical blood.</td>\n",
       "      <td>Nevertheless, that blood has not changed.</td>\n",
       "      <td>However, the blood is still the very same blood.</td>\n",
       "      <td>Even so, that blood continues to be the same.</td>\n",
       "      <td>Nonetheless, the blood remains unchanged.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>59gGMhffroM.002140-002312</td>\n",
       "      <td>71.33</td>\n",
       "      <td>5.73</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2140</td>\n",
       "      <td>2312</td>\n",
       "      <td>30.00</td>\n",
       "      <td>That carried generations of trauma</td>\n",
       "      <td>Generations of trauma were carried within it.</td>\n",
       "      <td>It held the burden of trauma passed down throu...</td>\n",
       "      <td>It bore the weight of trauma spanning across g...</td>\n",
       "      <td>This burden of trauma had been carried for gen...</td>\n",
       "      <td>The deep-rooted trauma spanned through many ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>59gGMhffroM.002312-002379</td>\n",
       "      <td>77.07</td>\n",
       "      <td>2.23</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2312</td>\n",
       "      <td>2379</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Across continents</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>59gGMhffroM.002379-002520</td>\n",
       "      <td>79.30</td>\n",
       "      <td>4.70</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2379</td>\n",
       "      <td>2520</td>\n",
       "      <td>30.00</td>\n",
       "      <td>And across oceans</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>59gGMhffroM.002660-002914</td>\n",
       "      <td>88.67</td>\n",
       "      <td>8.47</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2660</td>\n",
       "      <td>2914</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Circulating in my body as of this very moment</td>\n",
       "      <td>Currently coursing through my veins</td>\n",
       "      <td>Presently flowing within me</td>\n",
       "      <td>In my bloodstream right now</td>\n",
       "      <td>As of this moment, circulating in my body</td>\n",
       "      <td>Running through me at this very second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>59gGMhffroM.002938-003170</td>\n",
       "      <td>97.93</td>\n",
       "      <td>7.73</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>2938</td>\n",
       "      <td>3170</td>\n",
       "      <td>30.00</td>\n",
       "      <td>The human body can't survive without water</td>\n",
       "      <td>Water is essential for the survival of the hum...</td>\n",
       "      <td>Without water, the human body cannot endure.</td>\n",
       "      <td>The human body requires water in order to live.</td>\n",
       "      <td>Survival of the human body is impossible witho...</td>\n",
       "      <td>Water is a necessity for the human body to sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>59gGMhffroM.003170-003355</td>\n",
       "      <td>105.67</td>\n",
       "      <td>6.17</td>\n",
       "      <td>59gGMhffroM</td>\n",
       "      <td>3170</td>\n",
       "      <td>3355</td>\n",
       "      <td>30.00</td>\n",
       "      <td>But the heart still needs to pump blood</td>\n",
       "      <td>However, the heart must continue pumping blood.</td>\n",
       "      <td>Still, blood circulation requires the heart to...</td>\n",
       "      <td>Nevertheless, the heart remains responsible fo...</td>\n",
       "      <td>Yet, blood flow necessitates the ongoing actio...</td>\n",
       "      <td>Nonetheless, the heart must persist in its fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>61yO6Y8dgXw.000007-000157</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>61yO6Y8dgXw</td>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>29.97</td>\n",
       "      <td>Deaf people can qualify for Medicare or Medicaid.</td>\n",
       "      <td>Individuals who are deaf are eligible for Medi...</td>\n",
       "      <td>Deaf individuals have the possibility to meet ...</td>\n",
       "      <td>Medicare or Medicaid can be accessible to peop...</td>\n",
       "      <td>Qualification for Medicare or Medicaid is open...</td>\n",
       "      <td>Those who are deaf may be eligible for Medicar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>61yO6Y8dgXw.000160-000203</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1.43</td>\n",
       "      <td>61yO6Y8dgXw</td>\n",
       "      <td>160</td>\n",
       "      <td>203</td>\n",
       "      <td>29.97</td>\n",
       "      <td>What's the difference?</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                     ClipID  Beg(s)  Dur(s)    YouTubeID  StartFrame  \\\n",
       "45     45  59gGMhffroM.001980-002034   66.00    1.80  59gGMhffroM        1980   \n",
       "46     46  59gGMhffroM.002049-002140   68.30    3.03  59gGMhffroM        2049   \n",
       "47     47  59gGMhffroM.002140-002312   71.33    5.73  59gGMhffroM        2140   \n",
       "48     48  59gGMhffroM.002312-002379   77.07    2.23  59gGMhffroM        2312   \n",
       "49     49  59gGMhffroM.002379-002520   79.30    4.70  59gGMhffroM        2379   \n",
       "50     50  59gGMhffroM.002660-002914   88.67    8.47  59gGMhffroM        2660   \n",
       "51     51  59gGMhffroM.002938-003170   97.93    7.73  59gGMhffroM        2938   \n",
       "52     52  59gGMhffroM.003170-003355  105.67    6.17  59gGMhffroM        3170   \n",
       "53     53  61yO6Y8dgXw.000007-000157    0.23    5.01  61yO6Y8dgXw           7   \n",
       "54     54  61yO6Y8dgXw.000160-000203    5.34    1.43  61yO6Y8dgXw         160   \n",
       "\n",
       "    EndFrame    FPS                                            Caption  \\\n",
       "45      2034  30.00                                    Blood leaks out   \n",
       "46      2140  30.00             But that blood is still the same blood   \n",
       "47      2312  30.00                 That carried generations of trauma   \n",
       "48      2379  30.00                                  Across continents   \n",
       "49      2520  30.00                                  And across oceans   \n",
       "50      2914  30.00      Circulating in my body as of this very moment   \n",
       "51      3170  30.00         The human body can't survive without water   \n",
       "52      3355  30.00            But the heart still needs to pump blood   \n",
       "53       157  29.97  Deaf people can qualify for Medicare or Medicaid.   \n",
       "54       203  29.97                             What's the difference?   \n",
       "\n",
       "                                        GPT_Rephrase1  \\\n",
       "45                                             <none>   \n",
       "46       Yet, that blood remains the identical blood.   \n",
       "47      Generations of trauma were carried within it.   \n",
       "48                                             <none>   \n",
       "49                                             <none>   \n",
       "50                Currently coursing through my veins   \n",
       "51  Water is essential for the survival of the hum...   \n",
       "52    However, the heart must continue pumping blood.   \n",
       "53  Individuals who are deaf are eligible for Medi...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase2  \\\n",
       "45                                             <none>   \n",
       "46          Nevertheless, that blood has not changed.   \n",
       "47  It held the burden of trauma passed down throu...   \n",
       "48                                             <none>   \n",
       "49                                             <none>   \n",
       "50                        Presently flowing within me   \n",
       "51       Without water, the human body cannot endure.   \n",
       "52  Still, blood circulation requires the heart to...   \n",
       "53  Deaf individuals have the possibility to meet ...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase3  \\\n",
       "45                                             <none>   \n",
       "46   However, the blood is still the very same blood.   \n",
       "47  It bore the weight of trauma spanning across g...   \n",
       "48                                             <none>   \n",
       "49                                             <none>   \n",
       "50                        In my bloodstream right now   \n",
       "51    The human body requires water in order to live.   \n",
       "52  Nevertheless, the heart remains responsible fo...   \n",
       "53  Medicare or Medicaid can be accessible to peop...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase4  \\\n",
       "45                                             <none>   \n",
       "46      Even so, that blood continues to be the same.   \n",
       "47  This burden of trauma had been carried for gen...   \n",
       "48                                             <none>   \n",
       "49                                             <none>   \n",
       "50          As of this moment, circulating in my body   \n",
       "51  Survival of the human body is impossible witho...   \n",
       "52  Yet, blood flow necessitates the ongoing actio...   \n",
       "53  Qualification for Medicare or Medicaid is open...   \n",
       "54                                             <none>   \n",
       "\n",
       "                                        GPT_Rephrase5  \n",
       "45                                             <none>  \n",
       "46          Nonetheless, the blood remains unchanged.  \n",
       "47  The deep-rooted trauma spanned through many ge...  \n",
       "48                                             <none>  \n",
       "49                                             <none>  \n",
       "50             Running through me at this very second  \n",
       "51  Water is a necessity for the human body to sta...  \n",
       "52  Nonetheless, the heart must persist in its fun...  \n",
       "53  Those who are deaf may be eligible for Medicar...  \n",
       "54                                             <none>  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = merge1.combine_first(merge2).reset_index()\n",
    "merge.iloc[45:55]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5OLvH14uki3D"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
