import sys
import json
import numpy as np

import argparse

# by Dominik
# 

parser = argparse.ArgumentParser(f"""Given similarites matrix in npy file generated by h2s-similarities.py and a tsv file with clips in the same order as the similarity matrix, this parses the most and least similar clips to a file.

Usage: python3 {sys.argv[0]} [options] < in.tsv > out.json 2> debug-prints.txt

Input must be tsv with three columns: videoid, clipid, text.""")
parser.add_argument('-s', '--similarities',default="h2s-traindev-sim.npy",help="the npy file with similarity matrix")
parser.add_argument('-k', '--topk',default=10,help="how many positive and negative clips",type=int)
parser.add_argument('-d', '--debug',help="Whether to output also data fields useful for debugging and fact-checking.",
                    action='store_true') 
parser.add_argument('--dev', default=None,help="dev tsv")
parser.add_argument('--train', default=None,help="train tsv")
parser.set_defaults(debug=False)

args = parser.parse_args()


#data_dev = [x.split("\t") for x in sys.stdin.readlines()]

with open(args.dev,"r") as f:
    dev_tsv = [x.strip().split("\t") for x in f.readlines()]
dev_data = [(a,b,c.strip()) for a,b,c in dev_tsv]

with open(args.train,"r") as f:
    train_tsv = [x.strip().split("\t") for x in f.readlines()]
train_data = [(a,b,c.strip()) for a,b,c in train_tsv]





#with open("h2s.annotations.train.json","r") as f:
#    data_j = json.load(f)

#idx_to_clip = {i:d[1] for i,d in enumerate(data)}

#clips = {cl:t for _,cl,t in data}

similarities = np.load(args.similarities)
print("similarities loaded: ",similarities.shape, file=sys.stderr)


out_data = {}

least_k = args.topk
top_k = least_k+1 # there's the orig. sentence, we're avoiding it
for i in range(len(train_data)):
    trans = train_data[i][2]
    out_d = {}
    if args.debug:
        out_d["translation"] = trans

    print(trans,train_data[i][1],sep="\t",file=sys.stderr)
    s = similarities[i]

    # top values
    ind = np.argpartition(s, -top_k)[-top_k:]

    top_clips = []
    for k in ind:
        c = (s[k], # similarity
                *dev_data[k][1:] # clip id, translation
            )
        top_clips.append(c)
    top_clips = sorted(top_clips,key=lambda x:-x[0])
    for a,b,c in top_clips:
        print(a,b,c,sep="\t",file=sys.stderr)
    print(file=sys.stderr)

    out_d["positive"] = [x[1] for x in top_clips[1:]]

    # only for debugging
    if args.debug:
        out_d["_positive_sim"] = [float(x[0]) for x in top_clips[1:]]
        out_d["_positive_text"] = [x[2] for x in top_clips[1:]]


    # least values
    ind = np.argpartition(s, least_k)[:least_k]
    least_clips = []
    for k in ind:
        c = (s[k], # similarity
                *dev_data[k][1:] # clip id, translation
            )
        least_clips.append(c)
    least_clips = sorted(least_clips, key=lambda x:x[0])
    for a,b,c in least_clips:
        print(a,b,c,sep="\t",file=sys.stderr)
    print(file=sys.stderr)   

    out_d["negative"] = [x[1] for x in least_clips]
    if args.debug:
        out_d["_negative_sim"] = [float(x[0]) for x in least_clips]
        out_d["_negative_text"] = [x[2] for x in least_clips]

    clipid = train_data[i][1]
    out_data[clipid] = out_d

#with open(sys.argv[1],"w") as f:
json.dump(out_data, sys.stdout, indent=4)
